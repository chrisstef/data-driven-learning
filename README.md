# Fundamentals of Machine Learning (University of Applied Sciences Utrecht)

## What is on Canvas and what is on GitHub?
* On GitHub: example Notebooks, slides, extra material, exercises (in slides), data sets
* On Canvas: student manual, assignments, link to webinar recordings, overview of content per week

## Examples and exercises
Example code can be found in the Examples folder. During class, exercises will be shown on the slides. The data sets for these exercises can be found in the corresponding example folder. These are exercises you can make during the lesson to test your knowledge. You **don't** need to submit these.

## Resources and tips

### Python
* [Short cheatsheet](cheatsheet.md)
* [Extensive Python cheatsheet with examples](https://github.com/wilfredinni/python-cheatsheet#python-basics)
* [A more minimal cheatsheet](https://learnxinyminutes.com/docs/python3/)
* [Datacamp Python basics](https://campus.datacamp.com/courses/intro-to-python-for-data-science/chapter-1-python-basics)
* [Datacamp Python for data science](https://campus.datacamp.com/courses/intro-to-python-for-data-science/)
* [Markdown cheatsheet (for text in Notebooks)](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) 

### Mathematics
Using tools from data science and machine learning would not make a lot of sense without some understanding of mathematics and statistics. However, the focus of the course is on the application of data science, rather than the mathematical foundation. If I use formulas, I will not focus on the technical aspects, but explain what they do conceptually. If you need to catch up on math, you can use these links to the [Khan Academy](https://www.khanacademy.org/):

* [Basic algebra](https://www.khanacademy.org/math/algebra/introduction-to-algebra)
* [Equations and variables](https://www.khanacademy.org/math/algebra/one-variable-linear-equations)
* [Squares and roots](https://www.khanacademy.org/math/in-eighth-grade-math/squares-square-roots)
* [The coordinate plane and linear equations](https://www.khanacademy.org/math/algebra/two-var-linear-equations)
* [Exponents](https://www.khanacademy.org/math/pre-algebra/pre-algebra-exponents-radicals#pre-algebra-exponents) and [logarithms](https://www.khanacademy.org/math/algebra2/exponential-and-logarithmic-functions/introduction-to-logarithms/a/intro-to-logarithms)
* [Basic probability theory](https://www.khanacademy.org/math/probability/probability-geometry#probability-basics)

### Supplemental material by week ###
* [Week 1: video on mean, median and mode](https://www.youtube.com/watch?v=k3aKKasOmIw)
* [Week 1: video on distributions](https://www.youtube.com/watch?v=bPFNxD3Yg6U&t=612s)
* [Week 1: video on plotting distributions in Seaborn](https://www.youtube.com/watch?v=lTc7NU9XpWE)
* [Week 2: blog with overview with different types of bar charts and when to use them](https://chartio.com/learn/charts/bar-chart-complete-guide/)
* [Week 2: blog on count plots in Seaborn](https://towardsdatascience.com/hands-on-python-data-visualization-seaborn-count-plot-90e823599012)
* [Week 2: blog on scatterplot matrix in Seaborn](https://dzone.com/articles/what-when-amp-how-of-scatterplot-matrix-in-python)
* [Week 2: blog on correlation in Pandas and Seaborn](https://towardsdatascience.com/correlation-is-simple-with-seaborn-and-pandas-28c28e92701e)
* [Week 3: blog on linear regression in sklearn](https://stackabuse.com/linear-regression-in-python-with-scikit-learn/)
* [Week 3: another blog on linear regression, including residual plot](https://www.datacourses.com/evaluation-of-regression-models-in-scikit-learn-846/)
* [Week 4: blog with introduction to machine learning](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471)
* [Week 4: blog on k-NN](https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/)
* [Week 5: blog on decision tree (includes some math, but you can ignore this)](https://www.datacamp.com/community/tutorials/decision-tree-classification-python)
* [Week 5: blog on Random Forest (begin here)](https://www.datacamp.com/community/tutorials/random-forests-classifier-python)
* [Week 5: another blog on Random Forest, including parameter optimization](https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/)
* [Week 6: blog on text classification using bag-of-words-model and Naive Bayes](http://ethen8181.github.io/machine-learning/text_classification/basics/basics.html)

### Tips
* Google, [Stack Overflow](https://stackoverflow.com/) and [Cross Validated](https://stats.stackexchange.com/) are your friends. It’s not a shame to Google even really basic concepts.
* Your code should be properly commented (use `#`). Good commenting means you explain also why you do something, not just what you’re doing.
* Visualize and explore your data. Get acquainted with your data. Explore cases that deviate from the trend (outliers).
* Visualize your model predictions and [residuals](http://blog.minitab.com/blog/adventures-in-statistics-2/why-you-need-to-check-your-residual-plots-for-regression-analysis) to look for ways to improve your model. 
* Properly label your graphs and axes.
