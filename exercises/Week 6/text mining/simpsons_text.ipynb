{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpsons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook, we will pre-process lines of dialogue from the *Simpsons*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's read in the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('simpsons.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bart Simpson</td>\n",
       "      <td>Victory party under the slide!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Mr. Bergstrom! Mr. Bergstrom!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Do you know where I could find him?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_character_text                         spoken_words\n",
       "1        Lisa Simpson               Where's Mr. Bergstrom?\n",
       "3        Lisa Simpson           That life is worth living.\n",
       "7        Bart Simpson       Victory party under the slide!\n",
       "9        Lisa Simpson        Mr. Bergstrom! Mr. Bergstrom!\n",
       "11       Lisa Simpson  Do you know where I could find him?"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['raw_character_text'] == 'Lisa Simpson') | (df['raw_character_text'] == 'Bart Simpson')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the text and use it for our analysis, we need an object from `sklearn` called a `CountVectorizer`. Essentially, what it does is create a dictionary from a series of text. It lowercases the text and tokenizes it by using whitespace and interpunction as separations between words. I use a list of frequent English words ('stop words') that will not be counted: they are not informative enough.\n",
    "\n",
    "We will need to convert the text to Unicode, which is a standard text format. We do so by using `.values.astype('U')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14258 words in the vocabulary. A selection: ['anguished', 'angus', 'anima', 'animal', 'animals', 'animated', 'animation', 'animators', 'anka', 'ankle', 'ann', 'annapolis', 'anne', 'annie', 'anniversary', 'annnnd', 'announce', 'announcement', 'announcements', 'announcer']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #The CountVectorizer object\n",
    "\n",
    "text = df['spoken_words'].values.astype('U') #Taking the text from the df. We need to convert it to Unicode\n",
    "vect = CountVectorizer(stop_words='english') #Create the CV object, with English stop words\n",
    "vect = vect.fit(text) #We fit the model with the words from the review text\n",
    "feature_names = vect.get_feature_names() #Get the words from the vocabulary\n",
    "print(f\"There are {len(feature_names)} words in the vocabulary. A selection: {feature_names[500:520]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dictionary, we can count the occurences of each word for each review. This way, we can create a document-feature matrix, with documents (reviews) in the rows, and features (words) in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docu_feat = vect.transform(text) # make a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (24, 424)\t1\n",
      "  (40, 325)\t1\n",
      "  (45, 266)\t1\n",
      "  (63, 269)\t1\n",
      "  (74, 356)\t1\n",
      "  (80, 264)\t1\n",
      "  (82, 304)\t1\n",
      "  (98, 192)\t1\n",
      "  (100, 396)\t1\n",
      "  (151, 328)\t1\n",
      "  (156, 325)\t1\n",
      "  (157, 451)\t1\n",
      "  (163, 325)\t1\n",
      "  (164, 325)\t1\n",
      "  (186, 461)\t1\n",
      "  (207, 325)\t1\n",
      "  (210, 397)\t1\n",
      "  (231, 270)\t1\n",
      "  (237, 404)\t1\n",
      "  (259, 325)\t1\n",
      "  (287, 325)\t1\n",
      "  (294, 493)\t1\n",
      "  (295, 163)\t1\n",
      "  (318, 300)\t1\n",
      "  (321, 281)\t1\n",
      "  (356, 450)\t1\n",
      "  (358, 397)\t1\n",
      "  (362, 449)\t1\n",
      "  (366, 24)\t1\n",
      "  (366, 449)\t1\n",
      "  (386, 129)\t1\n",
      "  (387, 325)\t1\n",
      "  (388, 70)\t1\n",
      "  (394, 38)\t1\n",
      "  (394, 91)\t1\n",
      "  (396, 446)\t1\n",
      "  (398, 126)\t1\n",
      "  (410, 52)\t1\n",
      "  (410, 319)\t1\n",
      "  (410, 343)\t1\n",
      "  (413, 449)\t1\n",
      "  (419, 196)\t1\n",
      "  (428, 360)\t1\n",
      "  (464, 304)\t1\n"
     ]
    }
   ],
   "source": [
    "print(docu_feat[0:500,0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the matrix is mostly zeroes, they are left out to save memory. Instead, the positions of the cells that don't have a zero are spelled out, with their values. The first (row) number is the document (dialogue line), and the second (column) is the feature (word). This is a so-called sparse matrix, which saves a lot of memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
