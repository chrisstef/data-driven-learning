{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpsons: evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook, we will predict the character of lines of dialogue from the *Simpsons*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing ##\n",
    "\n",
    "\n",
    "First, let's start with the code to generate a document-feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bart Simpson</td>\n",
       "      <td>Victory party under the slide!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Mr. Bergstrom! Mr. Bergstrom!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Do you know where I could find him?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_character_text                         spoken_words\n",
       "1        Lisa Simpson               Where's Mr. Bergstrom?\n",
       "3        Lisa Simpson           That life is worth living.\n",
       "7        Bart Simpson       Victory party under the slide!\n",
       "9        Lisa Simpson        Mr. Bergstrom! Mr. Bergstrom!\n",
       "11       Lisa Simpson  Do you know where I could find him?"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('simpsons.csv')\n",
    "df = df.loc[(df['raw_character_text'] == 'Lisa Simpson') | (df['raw_character_text'] == 'Bart Simpson')]\n",
    "text = df['spoken_words'].values.astype('U') #Taking the text from the df. We need to convert it to Unicode\n",
    "vect = CountVectorizer(stop_words='english') #Create the CV object, with English stop words\n",
    "vect = vect.fit(text) #We fit the model with the words from the review text\n",
    "docu_feat = vect.transform(text) # make a matrix\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model ##\n",
    "\n",
    "Now, we will use the Na√Øve Bayes classifier from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB() #create the model\n",
    "X = docu_feat #the document-feature matrix is the X matrix\n",
    "y = df['raw_character_text'] #creating the y vector\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) #split the data and store it\n",
    "\n",
    "nb = nb.fit(X_train, y_train) #fit the model X=features, y=character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642904290429043"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Evaluate the model\n",
    "y_test_p = nb.predict(X_test)\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 63.7%, which is not great considering there are only two categories. What if we guessed the same category all the time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bart Simpson    0.544954\n",
       "Lisa Simpson    0.455046\n",
       "Name: raw_character_text, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['raw_character_text'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're doing about 9.3 percentage points better than when we guessed Bart all the time. Not great, but that's to be expected with such short lines of dialogue. Let's create a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bart pred</th>\n",
       "      <th>Lisa pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bart</th>\n",
       "      <td>3267</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lisa</th>\n",
       "      <td>1794</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bart pred  Lisa pred\n",
       "Bart       3267        911\n",
       "Lisa       1794       1603"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_test_p)\n",
    "cm = pd.DataFrame(cm, index=['Bart', 'Lisa'], columns=['Bart pred', 'Lisa pred'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bart has more lines than Lisa, which is how I figured out the ordering of the labels. However, you can also always get them using the `.classes_` attribute of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bart Simpson', 'Lisa Simpson'], dtype='<U12')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate precision and recall. Remember: precision is the proportion of the \"Bart\" predictions that is actually \"Bart\". Recall is the proportion of real \"Bart\" that is predicted as \"Bart\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision for Bart is: 0.6455245998814464\n",
      "The recall for Bart is: 0.7819530876017233\n",
      "The precision for Lisa is: 0.637629276054097\n",
      "The precision for Lisa is: 0.47188695908154255\n"
     ]
    }
   ],
   "source": [
    "print(f\"The precision for Bart is: {cm.iloc[0,0]/(cm.iloc[0,0]+cm.iloc[1,0])}\") #this uses the coordinates of the confustion matrix\n",
    "print(f\"The recall for Bart is: {cm.iloc[0,0]/(cm.iloc[0,0]+cm.iloc[0,1])}\")\n",
    "print(f\"The precision for Lisa is: {cm.iloc[1,1]/(cm.iloc[1,1]+cm.iloc[0,1])}\")\n",
    "print(f\"The precision for Lisa is: {cm.iloc[1,1]/(cm.iloc[1,1]+cm.iloc[1,0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do the same much shorter using a built-in function `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Bart Simpson       0.65      0.78      0.71      4178\n",
      "Lisa Simpson       0.64      0.47      0.54      3397\n",
      "\n",
      "    accuracy                           0.64      7575\n",
      "   macro avg       0.64      0.63      0.62      7575\n",
      "weighted avg       0.64      0.64      0.63      7575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_test_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The precision for \"Bart Simpson\" is 0.65, which means that out of a 100 lines that are predicted to be Bart's, only 65 are actually Bart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting probabilities instead of classes ##\n",
    "\n",
    "We can predict the probabilities of a line of dialogue using the method `.predict_proba`. Let's try it on a line of dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where's Mr. Bergstrom?\n",
      "[[0.02764282 0.97235718]]\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0,1])\n",
    "print(nb.predict_proba(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us an array/matrix of size 1x2 (you can see this from the double square brackets). Let's check out more lines. We need to get inside the array. Note that the array is two-dimensional (see the brackets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: 0. Where's Mr. Bergstrom?\n",
      "Bart: 0.02823148173303606, Lisa: 0.9717685182669633\n",
      "Line: 1. That life is worth living.\n",
      "Bart: 0.5962751907882123, Lisa: 0.4037248092117888\n",
      "Line: 2. Victory party under the slide!\n",
      "Bart: 0.8162185640113552, Lisa: 0.18378143598864466\n",
      "Line: 3. Mr. Bergstrom! Mr. Bergstrom!\n",
      "Bart: 0.0007086004249150008, Lisa: 0.9992913995750851\n",
      "Line: 4. Do you know where I could find him?\n",
      "Bart: 0.5373212010811312, Lisa: 0.4626787989188686\n",
      "Line: 5. The train, how like him... traditional, yet environmentally sound.\n",
      "Bart: 0.08794218252630742, Lisa: 0.9120578174736946\n",
      "Line: 6. I see he touched you, too.\n",
      "Bart: 0.5219607655971505, Lisa: 0.47803923440285034\n",
      "Line: 7. Hey, thanks for your vote, man.\n",
      "Bart: 0.9547850467242326, Lisa: 0.0452149532757656\n",
      "Line: 8. Well, you got that right. Thanks for your vote, girls.\n",
      "Bart: 0.7793934992698764, Lisa: 0.22060650073012048\n",
      "Line: 9. Well, don't sweat it. Just so long as a couple of people did... right, Milhouse?\n",
      "Bart: 0.8914004903805847, Lisa: 0.10859950961941423\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    prob = nb.predict_proba(X[i])\n",
    "    print(f\"Line: {i}. {df.iloc[i,1]}\")\n",
    "    print(f\"Bart: {prob[0,0]}, Lisa: {prob[0,1]}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to note here that the algorithm might have picked up (for fans of the Simpsons):\n",
    "* Lines 1, 2, 4, 6 provide too little information\n",
    "* Lines 0, 3: Bergstrom is Lisa's substitute teacher\n",
    "* Line 5: might be because of the complex words (and Lisa cares about the environment, too)\n",
    "* Line 7: 'Hey' and especially 'man' make this a very Bart-thing to say.\n",
    "* Line 8: Don't know, maybe 'girls'?\n",
    "* Line 9: Milhouse is Bart's friend and they regularly speak to each other\n",
    "\n",
    "**This is where the exercise ends. The rest is extra material.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the most predictive features ##\n",
    "\n",
    "If you want to check out which words/features predict the classes strongly, see the attribute `feature_log_prob_` of the Naive Bayes model. This array contains the (modelled) probabilities that a text from Lisa or Bart contains a certain word. Since a single word does not occur very often, these probabilities tend to be very small. That's why they are expressed in a logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.76115564, -10.16662075, -10.85976793, ...,  -9.25033002,\n",
       "        -10.85976793, -10.85976793],\n",
       "       [-10.09127332, -10.7844205 ,  -8.83851035, ..., -10.7844205 ,\n",
       "        -10.7844205 , -10.09127332]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14248</th>\n",
       "      <th>14249</th>\n",
       "      <th>14250</th>\n",
       "      <th>14251</th>\n",
       "      <th>14252</th>\n",
       "      <th>14253</th>\n",
       "      <th>14254</th>\n",
       "      <th>14255</th>\n",
       "      <th>14256</th>\n",
       "      <th>14257</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.761156</td>\n",
       "      <td>-10.166621</td>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-10.166621</td>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-10.166621</td>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-9.761156</td>\n",
       "      <td>-10.166621</td>\n",
       "      <td>-10.859768</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-10.166621</td>\n",
       "      <td>-10.166621</td>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-10.166621</td>\n",
       "      <td>-9.250330</td>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-10.859768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.091273</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-8.838510</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-10.091273</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-10.091273</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.685808</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-9.398126</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-10.091273</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>-10.091273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 14258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1          2          3          4          5      \\\n",
       "0  -9.761156 -10.166621 -10.859768 -10.166621 -10.859768 -10.166621   \n",
       "1 -10.091273 -10.784421  -8.838510 -10.784421 -10.091273 -10.784421   \n",
       "\n",
       "       6          7          8          9      ...      14248      14249  \\\n",
       "0 -10.859768  -9.761156 -10.166621 -10.859768  ... -10.859768 -10.859768   \n",
       "1 -10.784421 -10.784421 -10.784421 -10.091273  ...  -9.685808 -10.784421   \n",
       "\n",
       "       14250      14251      14252      14253      14254      14255  \\\n",
       "0 -10.859768 -10.166621 -10.166621 -10.859768 -10.166621  -9.250330   \n",
       "1  -9.398126 -10.784421 -10.784421 -10.091273 -10.784421 -10.784421   \n",
       "\n",
       "       14256      14257  \n",
       "0 -10.859768 -10.859768  \n",
       "1 -10.784421 -10.091273  \n",
       "\n",
       "[2 rows x 14258 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_df = pd.DataFrame(probs)#Let's make a dataframe out of it so it's more readable. The first column is for Bart, the second for Lisa. The rows are the words.\n",
    "probs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transpose (switch rows and columns) so that it's easier readable. Let's also add labels for Bart & Lisa and the word labels. We'll get the latter from the method *.get_feature_names()* from out CountVectorizer object *vect*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bart</th>\n",
       "      <th>Lisa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>-9.761156</td>\n",
       "      <td>-10.091273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007</th>\n",
       "      <td>-10.166621</td>\n",
       "      <td>-10.784421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.838510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>-10.166621</td>\n",
       "      <td>-10.784421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-10.091273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zur</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-10.091273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zz</th>\n",
       "      <td>-10.166621</td>\n",
       "      <td>-10.784421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzapp</th>\n",
       "      <td>-9.250330</td>\n",
       "      <td>-10.784421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>√£¬™tre</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-10.784421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>√£¬∫na</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-10.091273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14258 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bart       Lisa\n",
       "000     -9.761156 -10.091273\n",
       "007    -10.166621 -10.784421\n",
       "10     -10.859768  -8.838510\n",
       "1000   -10.166621 -10.784421\n",
       "10201  -10.859768 -10.091273\n",
       "...           ...        ...\n",
       "zur    -10.859768 -10.091273\n",
       "zz     -10.166621 -10.784421\n",
       "zzzapp  -9.250330 -10.784421\n",
       "√£¬™tre  -10.859768 -10.784421\n",
       "√£¬∫na   -10.859768 -10.091273\n",
       "\n",
       "[14258 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_df = probs_df.transpose()\n",
    "probs_df.index = vect.get_feature_names()\n",
    "probs_df.columns = [\"Bart\", \"Lisa\"]\n",
    "probs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's sort ascending to find the most predictive words. First for Bart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bart</th>\n",
       "      <th>Lisa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dad</th>\n",
       "      <td>-4.390518</td>\n",
       "      <td>-4.083689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nan</th>\n",
       "      <td>-4.602100</td>\n",
       "      <td>-4.540254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hey</th>\n",
       "      <td>-4.679751</td>\n",
       "      <td>-5.678475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>-4.766198</td>\n",
       "      <td>-4.725297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>-4.784422</td>\n",
       "      <td>-4.854831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>-4.817135</td>\n",
       "      <td>-4.748939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ll</th>\n",
       "      <td>-4.932842</td>\n",
       "      <td>-5.174949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-5.001835</td>\n",
       "      <td>-5.025519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom</th>\n",
       "      <td>-5.039685</td>\n",
       "      <td>-4.706778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve</th>\n",
       "      <td>-5.139456</td>\n",
       "      <td>-5.182302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>-5.155985</td>\n",
       "      <td>-5.121460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>-5.179595</td>\n",
       "      <td>-5.636926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>-5.200286</td>\n",
       "      <td>-6.480355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeah</th>\n",
       "      <td>-5.261346</td>\n",
       "      <td>-6.093073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gonna</th>\n",
       "      <td>-5.391708</td>\n",
       "      <td>-5.773785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>-5.466140</td>\n",
       "      <td>-5.709247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lisa</th>\n",
       "      <td>-5.586768</td>\n",
       "      <td>-6.723977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>-5.602273</td>\n",
       "      <td>-5.619635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>-5.612744</td>\n",
       "      <td>-6.120981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>-5.618021</td>\n",
       "      <td>-5.684554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bart      Lisa\n",
       "dad    -4.390518 -4.083689\n",
       "nan    -4.602100 -4.540254\n",
       "hey    -4.679751 -5.678475\n",
       "don    -4.766198 -4.725297\n",
       "oh     -4.784422 -4.854831\n",
       "just   -4.817135 -4.748939\n",
       "ll     -4.932842 -5.174949\n",
       "like   -5.001835 -5.025519\n",
       "mom    -5.039685 -4.706778\n",
       "ve     -5.139456 -5.182302\n",
       "know   -5.155985 -5.121460\n",
       "got    -5.179595 -5.636926\n",
       "man    -5.200286 -6.480355\n",
       "yeah   -5.261346 -6.093073\n",
       "gonna  -5.391708 -5.773785\n",
       "right  -5.466140 -5.709247\n",
       "lisa   -5.586768 -6.723977\n",
       "look   -5.602273 -5.619635\n",
       "come   -5.612744 -6.120981\n",
       "really -5.618021 -5.684554"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_df = probs_df.sort_values(\"Bart\", ascending=False)\n",
    "probs_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bart</th>\n",
       "      <th>Lisa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dad</th>\n",
       "      <td>-4.390518</td>\n",
       "      <td>-4.083689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>-6.205808</td>\n",
       "      <td>-4.470872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nan</th>\n",
       "      <td>-4.602100</td>\n",
       "      <td>-4.540254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom</th>\n",
       "      <td>-5.039685</td>\n",
       "      <td>-4.706778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>-4.766198</td>\n",
       "      <td>-4.725297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>-4.817135</td>\n",
       "      <td>-4.748939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>-4.784422</td>\n",
       "      <td>-4.854831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-5.001835</td>\n",
       "      <td>-5.025519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>-5.155985</td>\n",
       "      <td>-5.121460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ll</th>\n",
       "      <td>-4.932842</td>\n",
       "      <td>-5.174949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve</th>\n",
       "      <td>-5.139456</td>\n",
       "      <td>-5.182302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>-5.694982</td>\n",
       "      <td>-5.333382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did</th>\n",
       "      <td>-5.712273</td>\n",
       "      <td>-5.591464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>-5.602273</td>\n",
       "      <td>-5.619635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>-5.179595</td>\n",
       "      <td>-5.636926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hey</th>\n",
       "      <td>-4.679751</td>\n",
       "      <td>-5.678475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>-5.618021</td>\n",
       "      <td>-5.684554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>-5.466140</td>\n",
       "      <td>-5.709247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gonna</th>\n",
       "      <td>-5.391708</td>\n",
       "      <td>-5.773785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>-5.618021</td>\n",
       "      <td>-5.849947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bart      Lisa\n",
       "dad    -4.390518 -4.083689\n",
       "bart   -6.205808 -4.470872\n",
       "nan    -4.602100 -4.540254\n",
       "mom    -5.039685 -4.706778\n",
       "don    -4.766198 -4.725297\n",
       "just   -4.817135 -4.748939\n",
       "oh     -4.784422 -4.854831\n",
       "like   -5.001835 -5.025519\n",
       "know   -5.155985 -5.121460\n",
       "ll     -4.932842 -5.174949\n",
       "ve     -5.139456 -5.182302\n",
       "think  -5.694982 -5.333382\n",
       "did    -5.712273 -5.591464\n",
       "look   -5.602273 -5.619635\n",
       "got    -5.179595 -5.636926\n",
       "hey    -4.679751 -5.678475\n",
       "really -5.618021 -5.684554\n",
       "right  -5.466140 -5.709247\n",
       "gonna  -5.391708 -5.773785\n",
       "want   -5.618021 -5.849947"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_df = probs_df.sort_values(\"Lisa\", ascending=False)\n",
    "probs_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these have some overlap. That's because these words occur in both of their lines. If we want to know the most *distinctive* features, we have to subtract the numbers from each other<sup>*</sup>. Let's do that and sort.\n",
    "\n",
    "\\* <sub>For the mathematically inclined: you might be wondering why subtracting and not dividing (as Naive Bayes is based on the ratio of the two probabilities). First of all, well spotted! The reason is we're using log probabilities. A division is a subtraction in log units. If this is way over your head, don't worry - it's not that important.<sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bart</th>\n",
       "      <th>Lisa</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lu</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.011832</td>\n",
       "      <td>-2.847936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.145363</td>\n",
       "      <td>-2.714405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bergstrom</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.219471</td>\n",
       "      <td>-2.640297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>puzzle</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.386525</td>\n",
       "      <td>-2.473243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smithers</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.481835</td>\n",
       "      <td>-2.377933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professor</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.481835</td>\n",
       "      <td>-2.377933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congratulations</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.481835</td>\n",
       "      <td>-2.377933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bleeding</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.481835</td>\n",
       "      <td>-2.377933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buddhist</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.481835</td>\n",
       "      <td>-2.377933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gem</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.587196</td>\n",
       "      <td>-2.272572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tower</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.587196</td>\n",
       "      <td>-2.272572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>janey</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.587196</td>\n",
       "      <td>-2.272572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angelica</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.587196</td>\n",
       "      <td>-2.272572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thee</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.704979</td>\n",
       "      <td>-2.154789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yayyy</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.704979</td>\n",
       "      <td>-2.154789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.704979</td>\n",
       "      <td>-2.154789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mild</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.704979</td>\n",
       "      <td>-2.154789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neat</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.704979</td>\n",
       "      <td>-2.154789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitty</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.704979</td>\n",
       "      <td>-2.154789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flynt</th>\n",
       "      <td>-10.859768</td>\n",
       "      <td>-8.704979</td>\n",
       "      <td>-2.154789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Bart      Lisa      diff\n",
       "lu              -10.859768 -8.011832 -2.847936\n",
       "public          -10.859768 -8.145363 -2.714405\n",
       "bergstrom       -10.859768 -8.219471 -2.640297\n",
       "puzzle          -10.859768 -8.386525 -2.473243\n",
       "smithers        -10.859768 -8.481835 -2.377933\n",
       "professor       -10.859768 -8.481835 -2.377933\n",
       "congratulations -10.859768 -8.481835 -2.377933\n",
       "bleeding        -10.859768 -8.481835 -2.377933\n",
       "buddhist        -10.859768 -8.481835 -2.377933\n",
       "gem             -10.859768 -8.587196 -2.272572\n",
       "tower           -10.859768 -8.587196 -2.272572\n",
       "janey           -10.859768 -8.587196 -2.272572\n",
       "angelica        -10.859768 -8.587196 -2.272572\n",
       "thee            -10.859768 -8.704979 -2.154789\n",
       "yayyy           -10.859768 -8.704979 -2.154789\n",
       "global          -10.859768 -8.704979 -2.154789\n",
       "mild            -10.859768 -8.704979 -2.154789\n",
       "neat            -10.859768 -8.704979 -2.154789\n",
       "kitty           -10.859768 -8.704979 -2.154789\n",
       "flynt           -10.859768 -8.704979 -2.154789"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_df[\"diff\"] = probs_df[\"Bart\"] - probs_df[\"Lisa\"]\n",
    "probs_df = probs_df.sort_values(\"diff\")\n",
    "probs_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some very Lisa-like words here, like \"kitty\", \"neat\", \"buddhist\", \"bergstrom\".\n",
    "\n",
    "Now for Bart, sort ascending:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bart</th>\n",
       "      <th>Lisa</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lis</th>\n",
       "      <td>-5.954493</td>\n",
       "      <td>-10.091273</td>\n",
       "      <td>4.136780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ay</th>\n",
       "      <td>-7.333407</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>3.451013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carumba</th>\n",
       "      <td>-6.967948</td>\n",
       "      <td>-10.091273</td>\n",
       "      <td>3.123326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crap</th>\n",
       "      <td>-7.815245</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.969175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dude</th>\n",
       "      <td>-7.815245</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.969175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nah</th>\n",
       "      <td>-8.087179</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.697241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crappy</th>\n",
       "      <td>-8.151718</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.632703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gettin</th>\n",
       "      <td>-8.220711</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.563710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sis</th>\n",
       "      <td>-8.374861</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.409559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loser</th>\n",
       "      <td>-8.374861</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.409559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ass</th>\n",
       "      <td>-8.374861</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.409559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>-7.333407</td>\n",
       "      <td>-9.685808</td>\n",
       "      <td>2.352401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bastard</th>\n",
       "      <td>-8.461873</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.322548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyah</th>\n",
       "      <td>-8.461873</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.322548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shorts</th>\n",
       "      <td>-8.461873</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.322548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lookin</th>\n",
       "      <td>-7.768725</td>\n",
       "      <td>-10.091273</td>\n",
       "      <td>2.322548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ma</th>\n",
       "      <td>-7.458571</td>\n",
       "      <td>-9.685808</td>\n",
       "      <td>2.227238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poop</th>\n",
       "      <td>-8.557183</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.227238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dork</th>\n",
       "      <td>-8.662543</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.121877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teddy</th>\n",
       "      <td>-8.662543</td>\n",
       "      <td>-10.784421</td>\n",
       "      <td>2.121877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bart       Lisa      diff\n",
       "lis     -5.954493 -10.091273  4.136780\n",
       "ay      -7.333407 -10.784421  3.451013\n",
       "carumba -6.967948 -10.091273  3.123326\n",
       "crap    -7.815245 -10.784421  2.969175\n",
       "dude    -7.815245 -10.784421  2.969175\n",
       "nah     -8.087179 -10.784421  2.697241\n",
       "crappy  -8.151718 -10.784421  2.632703\n",
       "gettin  -8.220711 -10.784421  2.563710\n",
       "sis     -8.374861 -10.784421  2.409559\n",
       "loser   -8.374861 -10.784421  2.409559\n",
       "ass     -8.374861 -10.784421  2.409559\n",
       "awesome -7.333407  -9.685808  2.352401\n",
       "bastard -8.461873 -10.784421  2.322548\n",
       "nyah    -8.461873 -10.784421  2.322548\n",
       "shorts  -8.461873 -10.784421  2.322548\n",
       "lookin  -7.768725 -10.091273  2.322548\n",
       "ma      -7.458571  -9.685808  2.227238\n",
       "poop    -8.557183 -10.784421  2.227238\n",
       "dork    -8.662543 -10.784421  2.121877\n",
       "teddy   -8.662543 -10.784421  2.121877"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_df = probs_df.sort_values(\"diff\", ascending=False)\n",
    "probs_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is even more recognizable: \"lis\" (Lisa), \"ay\", \"carumba\", \"crap\", \"dude\" are instantly recognizable as Bart's.\n",
    "\n",
    "We might exclude some very infrequent words from this analysis. That exercise is left up to the reader.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
