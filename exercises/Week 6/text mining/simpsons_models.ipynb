{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how different models predict on the *Simpsons* data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing ##\n",
    "\n",
    "\n",
    "First, let's start with the code to generate a document-feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bart Simpson</td>\n",
       "      <td>Victory party under the slide!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Mr. Bergstrom! Mr. Bergstrom!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Do you know where I could find him?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_character_text                         spoken_words\n",
       "1        Lisa Simpson               Where's Mr. Bergstrom?\n",
       "3        Lisa Simpson           That life is worth living.\n",
       "7        Bart Simpson       Victory party under the slide!\n",
       "9        Lisa Simpson        Mr. Bergstrom! Mr. Bergstrom!\n",
       "11       Lisa Simpson  Do you know where I could find him?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('simpsons.csv')\n",
    "df = df.loc[(df['raw_character_text'] == 'Lisa Simpson') | (df['raw_character_text'] == 'Bart Simpson')]\n",
    "text = df['spoken_words'].values.astype('U') #Taking the text from the df. We need to convert it to Unicode\n",
    "vect = CountVectorizer(stop_words='english') #Create the CV object, with English stop words\n",
    "vect = vect.fit(text) #We fit the model with the words from the review text\n",
    "docu_feat = vect.transform(text) # make a matrix\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the models ##\n",
    "\n",
    "Now, we will use three different classifiers from `sklearn`: *Na√Øve Bayes*, *k-NN* and *Random Forest*. One approach is to simply fit all the models on the same data and see how they perform. For an even more precise estimate we'd do this for several train/test splits and average them. But now let's just stick to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = docu_feat #the document-feature matrix is the X matrix\n",
    "y = df['raw_character_text'] #creating the y vector\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) #split the data and store it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "nb = MultinomialNB() #create the model\n",
    "nb = nb.fit(X_train, y_train) #fit the model X=features, y=character\n",
    "\n",
    "#k-NN\n",
    "knn = KNeighborsClassifier() #create the model\n",
    "knn = knn.fit(X_train, y_train) #fit the model X=features, y=character\n",
    "\n",
    "#Random Forest\n",
    "rf = RandomForestClassifier() #create the model\n",
    "rf = rf.fit(X_train, y_train) #fit the model X=features, y=character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for Naive Bayes: 0.6361716171617162\n",
      "The accuracy for k-NN: 0.5566996699669967\n",
      "The accuracy for Random Forest: 0.6035643564356435\n"
     ]
    }
   ],
   "source": [
    "nb_score = nb.score(X_test, y_test)\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "\n",
    "print(f\"The accuracy for Naive Bayes: {nb_score}\")\n",
    "print(f\"The accuracy for k-NN: {knn_score}\")\n",
    "print(f\"The accuracy for Random Forest: {rf_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for Naive Bayes is best, followed by Random Forest and then k-NN. We could also look into precision and recall if we want to, but I'll leave that as an exercise for the reader.\n",
    "\n",
    "So one approach would be to take Naive Bayes as our model for now based on this exploration.\n",
    "\n",
    "If we wanted to improve its performance we might do some pre-processing on the data (e.g., stemming, adding features like utterance length, etc.). For example, the length of the utterance. Let's add it to the dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding another feature to our chosen model\n",
    "\n",
    "As an example, let's calculate the length of the dialogue line and add it to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bart Simpson</td>\n",
       "      <td>Victory party under the slide!</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Mr. Bergstrom! Mr. Bergstrom!</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Do you know where I could find him?</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_character_text                         spoken_words  length\n",
       "1        Lisa Simpson               Where's Mr. Bergstrom?      22\n",
       "3        Lisa Simpson           That life is worth living.      26\n",
       "7        Bart Simpson       Victory party under the slide!      30\n",
       "9        Lisa Simpson        Mr. Bergstrom! Mr. Bergstrom!      29\n",
       "11       Lisa Simpson  Do you know where I could find him?      35"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"spoken_words\"] = df[\"spoken_words\"].fillna(\"\") #There are NaN in that need to be removed. Let's fill them with an empty string\n",
    "df[\"length\"] = df[\"spoken_words\"].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there is an average difference here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_character_text\n",
       "Bart Simpson    41.49662\n",
       "Lisa Simpson    46.29698\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"raw_character_text\")[\"length\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, Lisa's lines are longer. Let's add the variable to the document-feature matrix. It's not a word but it can still be used as a column. We'll have to use numpy syntax for that, as the document-feature matrix is a numpy array, not a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plus = np.c_[X.toarray(), df[\"length\"]] #X.toarray() converts the sparse array to a normal array. This takes up somewhat more memory. However, not as much as making it into a dataframe. Then np.c_ concatenates the columns.\n",
    "X_train_plus, X_test_plus, y_train_plus, y_test_plus = train_test_split(X_plus, y, test_size=0.3) #split the data and store it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run another model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6357755775577558"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "nb = MultinomialNB() #create the model\n",
    "nb = nb.fit(X_train_plus, y_train_plus) #fit the model X=features, y=character\n",
    "nb_score = nb.score(X_test_plus, y_test_plus)\n",
    "nb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the improvement may be so slight that it really depends on the train-test split. So let's run a few more, including the original model, and calculate an average (this will take some time, about 5-10 minutes on my laptop): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb1_score = [] #the original data\n",
    "nb2_score = [] #the original data with extra length column\n",
    "\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) #the original data\n",
    "    X_train_plus, X_test_plus, y_train_plus, y_test_plus = train_test_split(X_plus, y, test_size=0.3) #data with extra column\n",
    "    \n",
    "    nb1 = MultinomialNB() #create the model\n",
    "    nb1 = nb1.fit(X_train, y_train) #train with original data\n",
    "    nb1_score.append(nb1.score(X_test, y_test)) #calculate scores and add to list\n",
    "    \n",
    "    nb2 = MultinomialNB() #create the model\n",
    "    nb2 = nb2.fit(X_train_plus, y_train_plus) #train with original data + length column\n",
    "    nb2_score.append(nb2.score(X_test_plus, y_test_plus)) #calculate scores and add to list\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores for the original model are: [0.635 0.642 0.633 0.632 0.632 0.647 0.631 0.644 0.638 0.644], mean 0.638\n",
      "The scores for the extended model are: [0.645 0.627 0.637 0.628 0.64  0.637 0.64  0.647 0.639 0.649], mean 0.639\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean, around\n",
    "\n",
    "print(f\"The scores for the original model are: {around(nb1_score, 3)}, mean {round(mean(nb1_score),3)}\")\n",
    "print(f\"The scores for the extended model are: {around(nb2_score, 3)}, mean {round(mean(nb2_score),3)}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores aren't that different at all, which I don't really understand... Given the large differences in length between Lisa and Bart's lines I think they would differ significantly. It's possible that I did something wrong. However, this is an example of how you could improve your model with some extra features after you've chosen a model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
